digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1637911595024 [label="
 (100, 10)" fillcolor=darkolivegreen1]
	1637911566080 [label=AddmmBackward0]
	1637911564784 -> 1637911566080
	1637911550528 [label="fc2.bias
 (10)" fillcolor=lightblue]
	1637911550528 -> 1637911564784
	1637911564784 [label=AccumulateGrad]
	1637911564976 -> 1637911566080
	1637911564976 [label=MulBackward0]
	1637911566800 -> 1637911564976
	1637911566800 [label=ReluBackward0]
	1637911567232 -> 1637911566800
	1637911567232 [label=AddmmBackward0]
	1637911567616 -> 1637911567232
	1637911550368 [label="fc1.bias
 (600)" fillcolor=lightblue]
	1637911550368 -> 1637911567616
	1637911567616 [label=AccumulateGrad]
	1637911567280 -> 1637911567232
	1637911567280 [label=ViewBackward0]
	1637911567664 -> 1637911567280
	1637911567664 [label=MaxPool2DWithIndicesBackward0]
	1637911566224 -> 1637911567664
	1637911566224 [label=ReluBackward0]
	1637911567472 -> 1637911566224
	1637911567472 [label=NativeBatchNormBackward0]
	1637911567328 -> 1637911567472
	1637911567328 [label=ConvolutionBackward0]
	1637911568048 -> 1637911567328
	1637911568048 [label=MaxPool2DWithIndicesBackward0]
	1637911566272 -> 1637911568048
	1637911566272 [label=ReluBackward0]
	1637911568192 -> 1637911566272
	1637911568192 [label=NativeBatchNormBackward0]
	1637911568288 -> 1637911568192
	1637911568288 [label=ConvolutionBackward0]
	1637911567856 -> 1637911568288
	1637911549248 [label="conv1.weight
 (8, 1, 3, 3)" fillcolor=lightblue]
	1637911549248 -> 1637911567856
	1637911567856 [label=AccumulateGrad]
	1637911568096 -> 1637911568288
	1637911549168 [label="conv1.bias
 (8)" fillcolor=lightblue]
	1637911549168 -> 1637911568096
	1637911568096 [label=AccumulateGrad]
	1637911565792 -> 1637911568192
	1637911161168 [label="batchnorm1.weight
 (8)" fillcolor=lightblue]
	1637911161168 -> 1637911565792
	1637911565792 [label=AccumulateGrad]
	1637911564544 -> 1637911568192
	1637911159488 [label="batchnorm1.bias
 (8)" fillcolor=lightblue]
	1637911159488 -> 1637911564544
	1637911564544 [label=AccumulateGrad]
	1637911566560 -> 1637911567328
	1637911549568 [label="conv2.weight
 (32, 8, 3, 3)" fillcolor=lightblue]
	1637911549568 -> 1637911566560
	1637911566560 [label=AccumulateGrad]
	1637911567952 -> 1637911567328
	1637911549808 [label="conv2.bias
 (32)" fillcolor=lightblue]
	1637911549808 -> 1637911567952
	1637911567952 [label=AccumulateGrad]
	1637911567520 -> 1637911567472
	1637911549728 [label="batchnorm2.weight
 (32)" fillcolor=lightblue]
	1637911549728 -> 1637911567520
	1637911567520 [label=AccumulateGrad]
	1637911567568 -> 1637911567472
	1637911549648 [label="batchnorm2.bias
 (32)" fillcolor=lightblue]
	1637911549648 -> 1637911567568
	1637911567568 [label=AccumulateGrad]
	1637911566656 -> 1637911567232
	1637911566656 [label=TBackward0]
	1637911567424 -> 1637911566656
	1637911549968 [label="fc1.weight
 (600, 2048)" fillcolor=lightblue]
	1637911549968 -> 1637911567424
	1637911567424 [label=AccumulateGrad]
	1637911566416 -> 1637911566080
	1637911566416 [label=TBackward0]
	1637911564448 -> 1637911566416
	1637911548448 [label="fc2.weight
 (10, 600)" fillcolor=lightblue]
	1637911548448 -> 1637911564448
	1637911564448 [label=AccumulateGrad]
	1637911566080 -> 1637911595024
}
